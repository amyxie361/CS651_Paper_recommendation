\section{Algorithms}

For the separated two parts of programs, we develop our algorithm differently. 

\subsection{Keywords recommendation algorithm}

Before implement recommendation algorithm, we first implemented the TF/IDF algorithm to preprocessing papers' abstracts into their keywords. Then we implemented the classic PageRank algorithm using GraphX for recommendation score computation.

\subsubsection{Preprocessing}

For computation effectiveness, we only keep the abstract of each paper. We first tokenize the abstract, then implemented the TF/IDF algorithm. Now we acquired the TF/IDF score for each token in each paper. Then we filter $k$ tokens with the highest score in each paper to be the paper's keywords. Then we construct an inverse map from keywords to paper index, meaning the token is a keyword for those papers. 
%We will also take the original author-generated keywords into consideration.

\subsubsection{PageRank for recommendation}

After we get the keywords to papers map, we implement the classic page rank algorithm to compute the score. 

First, according to the keywords from the input, we filter out the subgraphs. Each paper in this subgraph have the target tokens as their keywords. 

Next, we will first use GraphX to construct the citation network.  After we constructed the graph, we will implement the classic PageRank algorithm to establish a paper ranking. You can refer to \ref{alg:pagerank} to see detailed GraphX inplementation

\begin{algorithm}
  \SetKwInOut{Input}{Input}
  \SetKwInOut{Output}{Output}
  \SetKw{KwForEach}{foreach}
  \SetKw{KwIn}{in}
  \Input{Keywords list: $K = [k_1, k_2, ..., k_n]$, $G=(V, E)$, Term2PapersIndex: $T$ -> \{paper IDs with $T$ as a keyword\}}
  \Output{Filtered graph: $G=(V, E)$}
  \SetKwProg{Fn}{Function}{:}{end}
  \Fn{FilterGraph(Keywords)}{
    intersectedPaperIds := Intersection( \\
      Term2PapersIndex[$k_1$], \\
      Term2PapersIndex[$k_2$], \\
      ..., \\
      Term2PapersIndex[$k_n$] \\
    ) \\
    return subgraph of G containing IDs in intersectedPaperIds and associated edges
  }
  \caption{Keyword Filtering Algorithm}
  \label{alg:filter}
\end{algorithm}

\begin{algorithm}
 \SetKwInOut{Input}{Input}
 \SetKwInOut{Output}{Output}
 \SetKwInOut{Init}{Init}
 \SetKwProg{Fn}{Function}{:}{end}
 \Input{Keywords list: $K = [k_1, k_2, ..., k_n]$, $G=(V, E)$}
 \Output{Recommended paper list: $R = [r_1, r_2, ..., r_m]$}
 %initial
 \Fn{InitialGraph}{
 	JoinVertices\\
	map(edge.Attr =>$\frac{1}{edge.srcAttr}$)\\
	map(Vertice => 1.0)
 }
Init.Message $\gets$ 0.0\\
G $\gets$ \textbf{InitialGraph}.Filter(K)\\
set resetProb\\
set numIteration\\
\Fn{\textbf{vProg}(Vertex, sumMsg)}{
 	\Return{resetProb + (1.0 - resetProb) * msgSum}
 }
\Fn{\textbf{sendMsg}(Edge)}{
 	\Return{edge.srcAttr * edge.Attr}
 }
 \Fn{\textbf{mergeMsg}(aMsg, bMsg)}{
 	\Return{aMsg + bMsg}
 }
 G $\gets$ G.Pregel(initialMsg, maxIteration=numIteration, activateDirection=out, vProg, sendMsg, mergeMsg)\\
R $\gets$ G.Vertex.SortedBy(Vertex.Attr)\\
\Return{R}\\
 \caption{Paper Rank Algorithm}
 \label{alg:pagerank}
\end{algorithm}

Then we give recommendation paper list according to the ranking score, from the highest to the lowest.

\subsubsection{Pattern mining for recommendation}

To take advantage of the reading history for recommendation, we use pattern mining algorithms. 

We will find common patterns such as diamond pattern and triangle pattern to do recommendation. To find the interested classic papers, we find patterns on the original graph. To find the interested recent paper, we find the patterns on the reversed graph.

To simplify the description, we first consider the original graph. The recent paper version will be the same after we turn the graph into a reversed version.

Because the restrictions from GraphX, we design the algorithm to be a two-iteration algorithm. And the operations of each iteration will be different. In the first iteration, we filter out the papers cited by the papers in the reading history. We call them referred papers. In the second iteration, we mine the patterns out. You can refer to the detailed algorithm in Algorithm \ref{alg:pattern}

\begin{algorithm}
 \SetKwInOut{Input}{Input}
 \SetKwInOut{Output}{Output}
 \SetKwInOut{Init}{Init}
 \SetKwProg{Fn}{Function}{:}{end}
 \Input{Paper list: $P = [p_1, p_2, ..., p_n]$, $G=(V, E)$}
 \Output{Recommended paper list: $R = [r_1, r_2, ..., r_m]$}
 %initial
 \Fn{\textbf{InitialGraph}(P)}{
 	\eIf{Vertex.Id $\in$ P}{Vertex.Attr $\gets$ 1.0}
	{Vertex.Attr $\gets$ 0.0}
 }
Init.Message $\gets$ 0.0\\
G $\gets$ InitialGraph(P)\\
\Fn{\textbf{vProg1}(Vertex, sumMsg)}{
 	\Return{Vertex.Attr + sumMsg}
 }
\Fn{\textbf{sendMsg1}(Edge)}{
	\eIf{src.Attr > 0.0}{\Return{2.0}}{
 	\Return{0.0}}
 }
 \Fn{\textbf{mergeMsg1}(aMsg, bMsg)}{
 	\Return{$\max$(aMsg, bMsg)}
 }
 G $\gets$ G.Pregel(initialMsg, maxIteration=1, activateDirection=out, vProg1, sendMsg1, mergeMsg1)\\
 \Fn{\textbf{mapVertex}(Vertex)}{
 	\eIf{Vertex.Attr > 1.0}{Vertex.Attr$\gets$(1.0, 0.0)}{Vertex.Attr$\gets$(0.0, 0.0)}
 }
G $\gets$ G.mapVertex(mapVertex,Vertex)\\
\Fn{\textbf{vProg2}(Vertex, sumMsg)}{
 	\Return{(Vertex.Attr.\_1, sumMsg)}
 }
\Fn{\textbf{sendMsg2}(Edge)}{
	\eIf{src.Attr.\_1 > 0.0}{\Return{1.0}}{
 	\Return{0.0}}
 }
 \Fn{\textbf{mergeMsg2}(aMsg, bMsg)}{
 	\Return{aMsg + bMsg}
 }
 G $\gets$ G.Pregel(initialMsg, maxIteration=1, activateDirection=out, vProg2, sendMsg2, mergeMsg2)\\
R $\gets$ G.Vertiex.filter(Vertex.Attr.\_1 + Vertex.Attr.\_2 $\geq$ 2.0)\\
\Return{R}\\
 \caption{Pattern Mining Algorithm}
 \label{alg:pattern}
\end{algorithm}





