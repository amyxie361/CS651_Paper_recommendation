\section{Related Work} \label{sec:related-work}

There are number of researches on recommendation system, and the methods generally could be divided into machine learning and graph. Our approach is based on graph, one relevant work would be a service that provides real-time recommendations to tens of millions of mobile users in Twitter by implementing real-time motif detection on large dynamic graphs \cite{Gupta:2014}. In addition, similarity measures \cite{Goel2013} have been extensively studied in the area of information retrieval and networks, i.e. user similarity computation and the effects of user similarity in social media. Similarities between two entities are used for community detection, similarity search and recommendations, and most of them proposed for networks are based on graph structure, i.e. SimRank \cite{Jeh:2002}, Penetrating Rank \cite{Zhao:2009}. We proposed to use classic graph algorithms and network pattern mining methods for paper recommendation.

The papers mentioned above and our project are all based on large-scale graph processing. One suitable system for this kind of problem is Pregel \cite{Malewicz:2010}, where programs are expressed as a sequence of iterations. In each iteration, a vertex could receive the message sent from the previous iteration, then it sends messages to other vertices, updates its own state and outgoing edges. Since large-scale graphs that with millions of vertices and billions of edges are difficult to analyze, researchers have usually turned to distributed solutions, i.e. MapReduce \cite{Lin:2010}, or reduce the size of the graph by partitioning \cite{Karypis:1998}. In this work, we tried to explore GraphX, a new framework for distributed graph computation.

Furthermore, there is a pretty related work to our project \cite{DBLP}, which is about content-based citation recommendation. However, the method used in this paper is neural model instead of graph. They first embed all available documents into a vector space, and encoded text content of each document. Then, chose the nearest neighbours of the query document as candidates and reranked the candidates by another model trained, where this model takes a pair of documents as input and estimates the probability that $document_2$ should be cited in $document_1$. 

The evaluation methods \ref{Beel:2013} for recommendation system include online evaluations and offline evaluations. Online evaluation means that recommendations are shown to users as they use the real-world system, while offline evaluation \ref{Ricci:2010} includes precision, recall and F-measure. A good recommender system contributes to three features, recommendation accuracy, user satisfaction, and provider satisfaction, and leads to the question how these three features are to be quantified and compared. However, in our dataset, we do not have any of the needed data for evaluation: we do not have a rating for the predicted recommendations, we do not have a history data of users and we don't know the most important papers within a certain field. So in this work, we also proposed a novel way to measure the effectiveness of our recommendation system.

