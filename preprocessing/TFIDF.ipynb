{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark, random\n",
    "findspark.init(\"/u/cs451/packages/spark\")\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "sc = SparkContext(appName=\"YourTest\", master=\"local[2]\", conf=SparkConf().set('spark.ui.port', random.randrange(4000,5000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import random\n",
    "spark = SparkSession.builder.appName(\"YourTest\").master(\"local[2]\").config('spark.ui.port', random.randrange(4000,5000)).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "import re\n",
    "from math import log\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import LongType, StringType\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower(line):\n",
    "    w=[]\n",
    "    for word in line:\n",
    "        w.append(word.lower())\n",
    "    return w\n",
    "\n",
    "def tokenize(line):\n",
    "    return re.findall(r\"[A-Za-z0-9_-]+\",line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract=sc.textFile(\"abstract.txt\").map(lambda l: tokenize(l))\n",
    "b=abstract.map(lambda l: l[0]).map(lambda x: (x, ))\n",
    "c=abstract.map(lambda l: lower(l)).map(lambda l: l[1:]).map(lambda x: (x, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1=b.toDF().withColumnRenamed( \"_1\" , \"paper_id\").withColumn(\"id\", monotonically_increasing_id())\n",
    "corpus2=c.toDF().withColumnRenamed( \"_1\" , \"documents\").withColumn(\"id\", monotonically_increasing_id())\n",
    "corpus = corpus1.join(corpus2, \"id\", \"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "explode=corpus.select(explode(\"documents\"),\"paper_id\", \"documents\").withColumnRenamed(\"col\" , \"token\")\n",
    "\n",
    "withtf=explode.groupBy(\"paper_id\",\"token\").count().withColumnRenamed(\"count\" , \"tf\")\n",
    "\n",
    "withdf=withtf.groupBy(\"token\").agg(countDistinct(\"paper_id\").alias(\"df\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=b.count()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "withidf1=withdf.withColumn(\"deno\", lit(num).cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "withidf2=withidf1.withColumn(\"nume\", col(\"df\")+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "withidf3=withidf2.withColumn(\"idf\", log10(col(\"deno\")/col(\"nume\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=withtf.join(withidf3,\"token\",\"left\").withColumn(\"tf_idf\",col(\"tf\")*col(\"idf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---+-----+-------+-----+------------------+------------------+\n",
      "|   token|paper_id| tf|   df|   deno| nume|               idf|            tf_idf|\n",
      "+--------+--------+---+-----+-------+-----+------------------+------------------+\n",
      "| andnbsp|  796734|125|    2|1669283|    3| 5.745408715823863| 718.1760894779828|\n",
      "|   xlink| 1593453|126|  217|1669283|  218|3.8840734769389207|489.39325809430403|\n",
      "|    hack| 1342613|121|  225|1669283|  226|3.8684215313961245|468.07900529893107|\n",
      "|informix|  125180| 99|  106|1669283|  107| 4.193146192858316|415.12147309297325|\n",
      "|    soho| 2297465| 91|   96|1669283|   97| 4.235758236277281|385.45399950123254|\n",
      "|     mml| 1927782| 95|  153|1669283|  154| 4.035009249707063|383.32587872217096|\n",
      "|    thgr|  711390| 93|  132|1669283|  133|4.0986783295764395| 381.1770846506089|\n",
      "|    nbsp|  882067| 72|    9|1669283|   10| 5.222529970543525|376.02215787913383|\n",
      "|   xlink| 1680209| 96|  217|1669283|  218|3.8840734769389207| 372.8710537861364|\n",
      "|ext-link| 1593453| 84|   71|1669283|   72| 4.365197474112257| 366.6765878254296|\n",
      "|  tuxedo|  171152| 71|   12|1669283|   13| 5.108586618236688| 362.7096498948049|\n",
      "|     jmx|  664634| 76|   46|1669283|   47| 4.550432112607808| 345.8328405581934|\n",
      "|   xlink| 1708432| 87|  217|1669283|  218|3.8840734769389207| 337.9143924936861|\n",
      "|    html| 2095370|135| 5658|1669283| 5659|2.4697902766081974| 333.4216873421066|\n",
      "|    jini| 2155253| 86|  270|1669283|  271|  3.78956067966912| 325.9022184515443|\n",
      "|  i-mode|   68470| 73|   63|1669283|   64| 4.416349996559639| 322.3935497488536|\n",
      "|   emacs| 2137814| 79|  147|1669283|  148| 4.052268255148568|320.12919215673685|\n",
      "|     xml|   26487|149|12370|1669283|12371|2.1301251636445175| 317.3886493830331|\n",
      "|   basic| 2097437|220|60726|1669283|60727|1.4391481436549045|  316.612591604079|\n",
      "|incident|   89010|113| 3092|1669283| 3093|2.7321500505403464|308.73295571105916|\n",
      "+--------+--------+---+-----+-------+-----+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf.orderBy(col(\"tf_idf\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcIdf(df):\n",
    "    return log((D+1)/(df + 1),10)\n",
    "spark.udf.register(\"calcIdfWithPython\", calcIdf, LongType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcIdf_udf=udf(calcIdf, LongType())\n",
    "df.select(\"id\", squared_udf(\"id\").alias(\"id_squared\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=withdf.select(\"df\").rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=withdf.select(\"df\").collect().map(_(0)).toList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withidf=withdf.withColumn(\"idf\", log((D+1)/(col(\"df\") + 1),10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explode=spark.sql(\"SELECT explode(documents) AS token, paper_id, documents \\\n",
    "FROM corpus\").cache()\n",
    "explode.createOrReplaceTempView(\"explode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withtf=spark.sql(\"SELECT COUNT(documents) AS tf, paper_id, token \\\n",
    "FROM explode \\\n",
    "GROUP BY paper_id, token\").cache()\n",
    "withtf.createOrReplaceTempView(\"withtf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withdf=spark.sql(\"SELECT COUNT(DISTINCT paper_id) AS DF, token \\\n",
    "FROM withtf \\\n",
    "GROUP BY token\").cache()\n",
    "withdf.createOrReplaceTempView(\"withdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=spark.sql(\"SELECT COUNT(DF) AS count \\\n",
    "FROM withdf\")\n",
    "c.first()[\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1618522',\n",
       "  'In',\n",
       "  'dealing',\n",
       "  'with',\n",
       "  'the',\n",
       "  'container',\n",
       "  'bloat',\n",
       "  'problem',\n",
       "  'we',\n",
       "  'identify',\n",
       "  'five',\n",
       "  'memory',\n",
       "  'compaction',\n",
       "  'techniques',\n",
       "  'which',\n",
       "  'can',\n",
       "  'be',\n",
       "  'used',\n",
       "  'to',\n",
       "  'reduce',\n",
       "  'the',\n",
       "  'footprint',\n",
       "  'of',\n",
       "  'the',\n",
       "  'large',\n",
       "  'number',\n",
       "  'of',\n",
       "  'small',\n",
       "  'objects',\n",
       "  'that',\n",
       "  'make',\n",
       "  'these',\n",
       "  'containers',\n",
       "  'Using',\n",
       "  'these',\n",
       "  'techniques',\n",
       "  'we',\n",
       "  'describe',\n",
       "  'two',\n",
       "  'alternative',\n",
       "  'methods',\n",
       "  'for',\n",
       "  'more',\n",
       "  'efficient',\n",
       "  'encoding',\n",
       "  'of',\n",
       "  'the',\n",
       "  'JRE',\n",
       "  's',\n",
       "  'ubiquitous',\n",
       "  'HashMap',\n",
       "  'data',\n",
       "  'structure',\n",
       "  'and',\n",
       "  'present',\n",
       "  'a',\n",
       "  'mathematical',\n",
       "  'model',\n",
       "  'in',\n",
       "  'which',\n",
       "  'the',\n",
       "  'footprint',\n",
       "  'of',\n",
       "  'this',\n",
       "  'can',\n",
       "  'be',\n",
       "  'analyzed',\n",
       "  'The',\n",
       "  'fused',\n",
       "  'hashing',\n",
       "  'encoding',\n",
       "  'method',\n",
       "  'reduces',\n",
       "  'memory',\n",
       "  'overhead',\n",
       "  'by',\n",
       "  '20',\n",
       "  '---45',\n",
       "  'on',\n",
       "  'a',\n",
       "  '32-bit',\n",
       "  'environment',\n",
       "  'and',\n",
       "  '45',\n",
       "  '---65',\n",
       "  'on',\n",
       "  'a',\n",
       "  '64-bit',\n",
       "  'environment',\n",
       "  'This',\n",
       "  'encoding',\n",
       "  'guarantees',\n",
       "  'these',\n",
       "  'figures',\n",
       "  'as',\n",
       "  'lower',\n",
       "  'bound',\n",
       "  'regardless',\n",
       "  'of',\n",
       "  'the',\n",
       "  'distribution',\n",
       "  'of',\n",
       "  'keys',\n",
       "  'in',\n",
       "  'hash',\n",
       "  'buckets',\n",
       "  'The',\n",
       "  'more',\n",
       "  'opportunistic',\n",
       "  'squashed',\n",
       "  'hashing',\n",
       "  'achieves',\n",
       "  'expected',\n",
       "  'savings',\n",
       "  'of',\n",
       "  '25',\n",
       "  '---70',\n",
       "  'on',\n",
       "  'a',\n",
       "  '32-bit',\n",
       "  'environment',\n",
       "  'and',\n",
       "  '30',\n",
       "  '---75',\n",
       "  'on',\n",
       "  'a',\n",
       "  '64-bit',\n",
       "  'environments',\n",
       "  'but',\n",
       "  'these',\n",
       "  'savings',\n",
       "  'can',\n",
       "  'degrade',\n",
       "  'and',\n",
       "  'are',\n",
       "  'not',\n",
       "  'guaranteed',\n",
       "  'against',\n",
       "  'bad',\n",
       "  'and',\n",
       "  'unlikely',\n",
       "  'distribution',\n",
       "  'of',\n",
       "  'keys',\n",
       "  'to',\n",
       "  'buckets',\n",
       "  'Both',\n",
       "  'techniques',\n",
       "  'are',\n",
       "  'applicable',\n",
       "  'and',\n",
       "  'give',\n",
       "  'merit',\n",
       "  'to',\n",
       "  'an',\n",
       "  'implementation',\n",
       "  'of',\n",
       "  'HashSet',\n",
       "  'which',\n",
       "  'is',\n",
       "  'independent',\n",
       "  'of',\n",
       "  'that',\n",
       "  'of',\n",
       "  'HashMap',\n",
       "  'Benchmarking',\n",
       "  'using',\n",
       "  'the',\n",
       "  'SPECjvm2008',\n",
       "  'SPECjbb2005',\n",
       "  'and',\n",
       "  'DaCapo',\n",
       "  'suites',\n",
       "  'does',\n",
       "  'not',\n",
       "  'demonstrate',\n",
       "  'significant',\n",
       "  'major',\n",
       "  'slowdown',\n",
       "  'or',\n",
       "  'speedup',\n",
       "  'For',\n",
       "  'TreeMap',\n",
       "  'we',\n",
       "  'show',\n",
       "  'two',\n",
       "  'encodings',\n",
       "  'which',\n",
       "  'reduce',\n",
       "  'the',\n",
       "  'overhead',\n",
       "  'of',\n",
       "  'tree',\n",
       "  'nodes',\n",
       "  'by',\n",
       "  '43',\n",
       "  '46',\n",
       "  'on',\n",
       "  'a',\n",
       "  '32-bit',\n",
       "  'environment',\n",
       "  'and',\n",
       "  '55',\n",
       "  '73',\n",
       "  'on',\n",
       "  'a',\n",
       "  '64-bit',\n",
       "  'environment',\n",
       "  'These',\n",
       "  'also',\n",
       "  'give',\n",
       "  'to',\n",
       "  'separating',\n",
       "  'the',\n",
       "  'implementation',\n",
       "  'of',\n",
       "  'TreeSet',\n",
       "  'from',\n",
       "  'that',\n",
       "  'of',\n",
       "  'TreeMap',\n",
       "  'which',\n",
       "  'gives',\n",
       "  'rise',\n",
       "  'to',\n",
       "  'footprint',\n",
       "  'reduction',\n",
       "  'of',\n",
       "  '59',\n",
       "  '54',\n",
       "  'on',\n",
       "  'a',\n",
       "  '32-bit',\n",
       "  'environment',\n",
       "  'and',\n",
       "  '61',\n",
       "  '77',\n",
       "  'on',\n",
       "  'a',\n",
       "  '64-bit',\n",
       "  'environment']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract.filter(lambda x: x[0]=='1618522').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
